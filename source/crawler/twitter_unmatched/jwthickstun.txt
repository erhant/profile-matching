{"bio": "", "born": "", "followers": "", "following": "", "handle": "", "joined": "", "location": "", "name": "", "photo": null, "site": "", "tweets": ["Our #ICML2020 talk on bayesian source separation with deep generative priors is now available on YouTube: https://youtu.be/nxvKapBr5vs. Joint work with @vivjay30Source Separation with Deep Generative Priors - ICML 2020 PresentationWe explore a bayesian approach to source separation that uses cutting edge generative models. This is our talk from ICML 2020. Paper: https://arxiv.org/pdf/2...youtube.com311", "", "Fantastic open-source implementation that reproduces results of the recent #DiffWave paper!Quote TweetSharvil Nanavati@snrrrub \u00b7 Oct 14There's a new pretrained #DiffWave model up on https://github.com/lmnt-com/diffwave\u2026 that's trained to 1M steps. It sounds clearer than the previous pretrained model - listen to the audio samples at https://lmnt.com/assets/diffwave.1", "I had trouble understanding the precise specification of the transformer architecture from descriptions in the literature. So I reverse-engineered the transformer equations by looking at some standard implementations. Here are my notes.\n\nhttps://homes.cs.washington.edu/~thickstn/docs/transformers.pdf\u2026110", ""]}