{"bio": "PhD student in machine learning @ShaLabUSC.", "born": "", "followers": "465 Followers", "following": "1,233 Following", "handle": "@seba1511", "joined": "Joined May 2010", "location": "Los Angeles, CA", "name": "S\u00e9b Arnold", "photo": "https://pbs.twimg.com/profile_images/915840040067932160/fGxNP4b-_400x400.jpg", "site": "seba1511.net", "tweets": ["As some already guessed it, A and B are actually the same RL algorithm (A2C), sharing the exact same code, same hardware, same hyperparameters... except the epsilon value to avoid division by zero in the optimizer (one is `eps=1e-5`, the other `eps=1e-7`)Quote TweetAntonin Raffin@araffin2 \u00b7 Nov 18Two algorithms, A and B, 10 random seeds, 10M steps on Atari Breakout, which one is the best?\n\n(wrong answers recommended, A and B reveal will come later)20106549", "I am currently on the academic job market. Looking forward to spending the foreseeable future working at the intersection and forefront of AI and Medicine.\n\nhttp://pranavrajpurkar.com69173", "How can we use large offline datasets for accelerating the learning of new tasks? We can transfer skills!\nCheck out our #CoRL2020 paper on efficient skill transfer with learned skill priors!\nPaper: https://arxiv.org/abs/2010.11944\nWebsite & Code: https://clvrai.com/spirl\n\nThread(1/8)GIF1620", "RL folks, meet your newest friend: THE LOGISTIC BELLMAN ERROR\n\nA convex loss function derived from first principles of MDP theory that leads to practical RL algorithms that can be implemented without *any* approximation of the theory.\n\nPreprint: https://arxiv.org/abs/2010.11151\n \n1/187138644", "Replying to @daniel_bilar and @hardmaruV v few people teach students who to properly read anything, let alone research papersThe following media includes potentially sensitive content. Change settingsView12182"]}