{"bio": "Computer science professor at Penn. I study machine learning, privacy, and fairness. Our new book out now: The Ethical Algorithm. http://amzn.to/2kF40u3", "born": "", "followers": "5,565 Followers", "following": "474 Following", "handle": "@Aaroth", "joined": "Joined May 2007", "location": "Philadelphia, PA", "name": "Aaron Roth", "photo": "https://pbs.twimg.com/profile_images/1285635401353498624/XUsGkLp8_400x400.jpg", "site": "", "tweets": ["Indeed, a very clean result linking DP and generalization in ML! \n\nAuthors on Twitter include @crispy_jung @SethVNeel @Aaroth @moshenfeldQuote TweetBoaz Barak@boazbaraktcs \u00b7 Nov 182/6\nhttps://arxiv.org/abs/1909.03577 (ITCS 20) gives \"transfer theorem\" for translating privacy guarantees to generalization performance. \n\nThough such results were known (respecting privacy \u21d2 can't overfit) previous proofs often \"hairy\". This gives \"book proof\" with much better bounds.Show this thread2318", "Very nice simplification of permute and flip.Quote TweetThomas Steinke@shortstein \u00b7 Nov 16Answering my question: Permute-and-flip is equivalent to adding exponential noise to each value and returning the noisy argmax. I think that makes the algorithm even more elegant.  twitter.com/shortstein/sta\u2026Show this thread10", "Both of our kids' schools are shutting down this week because of COVID; please wear a mask and do not host gatherings in your home.2139", "This is a very nice and complete break of InstaHide by some of my Google colleagues and others: https://arxiv.org/abs/2011.05315\n\nTL;DR: This scheme does not work, as the \"encrypted\" images can be largely recovered. \n\n1/5357143", ""]}